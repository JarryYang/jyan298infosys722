{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('JunqiYang722').getOrCreate()\n",
    "#Read csv file\n",
    "df = spark.read.csv('AirQuality.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+--------+---+----+----+---+----+----+----+-------+----+----+--------+---------+----+----+---+---+-----+----------+----------+-----+\n",
      "|          time|station|AMB_TEMP|CH4|  CO|NMHC| NO| NO2| Nox|  O3|PH_RAIN|PM10|PM25|RAINFALL|RAIN_COND|  RH| SO2|THC|UVB|WD_HR|WIND_DIREC|WIND_SPEED|WS_HR|\n",
      "+--------------+-------+--------+---+----+----+---+----+----+----+-------+----+----+--------+---------+----+----+---+---+-----+----------+----------+-----+\n",
      "| 2015/1/1 0:00|Banqiao|    16.0|2.1|0.79|0.14|1.2|16.0|17.0|37.0|     NR| 177|78.0|      NR|       NR|57.0|12.0|2.2|0.0| 69.0|      69.0|       4.7|  4.2|\n",
      "| 2015/1/1 1:00|Banqiao|    16.0|2.1| 0.8|0.15|1.3|16.0|17.0|36.0|     NR| 178|77.0|      NR|       NR|57.0|11.0|2.2|0.0| 67.0|      65.0|       4.0|  4.0|\n",
      "| 2015/1/1 2:00|Banqiao|    16.0|2.1|0.71|0.13|1.0|13.0|14.0|38.0|     NR| 163|72.0|      NR|       NR|57.0| 8.0|2.2|0.0| 63.0|      53.0|       3.7|  3.5|\n",
      "| 2015/1/1 3:00|Banqiao|    15.0|2.0|0.66|0.12|0.8|11.0|12.0|39.0|     NR| 147|65.0|      NR|       NR|58.0| 6.5|2.2|0.0| 63.0|      63.0|       4.1|  3.3|\n",
      "| 2015/1/1 4:00|Banqiao|    15.0|2.0|0.53|0.11|0.6|10.0|11.0|38.0|     NR| 131|56.0|      NR|       NR|58.0| 5.5|2.1|0.0| 69.0|      67.0|       3.0|  3.1|\n",
      "| 2015/1/1 5:00|Banqiao|    14.0|2.0| 0.5|0.11|0.8|11.0|12.0|37.0|     NR| 112|46.0|      NR|       NR|57.0| 5.7|2.1|0.0| 68.0|      62.0|       2.9|  3.3|\n",
      "| 2015/1/1 6:00|Banqiao|    14.0|2.0|0.57|0.14|1.4|18.0|19.0|29.0|     NR| 103|45.0|      NR|       NR|57.0| 5.8|2.1|0.0| 74.0|      70.0|       3.6|  2.2|\n",
      "| 2015/1/1 7:00|Banqiao|    14.0|2.0|0.61|0.14|2.3|17.0|20.0|27.0|     NR| 104|42.0|      NR|       NR|56.0| 6.5|2.2|0.2| 66.0|      72.0|       3.1|  3.0|\n",
      "| 2015/1/1 8:00|Banqiao|    14.0|2.0|0.59|0.13|2.9|15.0|18.0|29.0|     NR| 111|45.0|      NR|       NR|53.0| 6.8|2.1|0.7| 71.0|      73.0|       2.8|  3.3|\n",
      "| 2015/1/1 9:00|Banqiao|    14.0|2.0| 0.6|0.14|4.1|16.0|20.0|29.0|     NR| 111|46.0|      NR|       NR|50.0| 5.9|2.1|1.6| 73.0|      68.0|       3.6|  3.2|\n",
      "|2015/1/1 10:00|Banqiao|    15.0|2.0|0.55|0.13|4.2|14.0|18.0|35.0|     NR| 100|41.0|      NR|       NR|47.0| 5.2|2.1|3.0| 69.0|      68.0|       4.3|  3.5|\n",
      "|2015/1/1 11:00|Banqiao|    14.0|2.0|0.51|0.11|3.8|13.0|17.0|39.0|     NR|  92|38.0|      NR|       NR|45.0| 4.5|2.1|3.6| 73.0|      84.0|       3.0|  3.5|\n",
      "|2015/1/1 12:00|Banqiao|    15.0|2.0|0.47|0.11|4.2|12.0|16.0|41.0|     NR|  83|36.0|      NR|       NR|44.0| 3.7|2.1|4.1| 71.0|      67.0|       4.9|  3.3|\n",
      "|2015/1/1 13:00|Banqiao|    14.0|2.0|0.42|0.09|2.9|10.0|13.0|43.0|     NR|  76|31.0|      NR|       NR|46.0| 3.3|2.1|3.2| 67.0|      69.0|       4.3|  3.9|\n",
      "|2015/1/1 14:00|Banqiao|    14.0|2.0|0.41| 0.1|3.0|12.0|15.0|39.0|     NR|  73|25.0|      NR|       NR|49.0| 3.0|2.0|1.6| 69.0|      67.0|       3.9|  3.6|\n",
      "|2015/1/1 15:00|Banqiao|    13.0|2.0|0.42| 0.1|2.4|13.0|16.0|36.0|     NR|  66|25.0|      NR|       NR|52.0| 3.0|2.0|0.6| 71.0|      73.0|       3.5|  3.4|\n",
      "|2015/1/1 16:00|Banqiao|    13.0|2.0|0.45|0.11|1.8|14.0|16.0|33.0|     NR|  61|24.0|      NR|       NR|53.0| 3.2|2.1|0.1| 68.0|      69.0|       3.2|  3.5|\n",
      "|2015/1/1 17:00|Banqiao|    13.0|2.0|0.46|0.12|2.0|16.0|18.0|31.0|     NR|  57|20.0|      NR|       NR|53.0| 3.0|2.1|0.0| 68.0|      70.0|       3.9|  3.5|\n",
      "|2015/1/1 18:00|Banqiao|    13.0|2.0|0.45|0.13|2.5|18.0|20.0|29.0|     NR|  50|22.0|      NR|       NR|53.0| 3.2|2.1|0.0| 73.0|      85.0|       1.9|  2.8|\n",
      "|2015/1/1 19:00|Banqiao|    13.0|2.0|0.48|0.15|2.8|21.0|24.0|24.0|     NR|  45|20.0|      NR|       NR|55.0| 3.3|2.1|0.0| 84.0|      95.0|       1.7|  1.7|\n",
      "+--------------+-------+--------+---+----+----+---+----+----+----+-------+----+----+--------+---------+----+----+---+---+-----+----------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time: string (nullable = true)\n",
      " |-- station: string (nullable = true)\n",
      " |-- AMB_TEMP: double (nullable = true)\n",
      " |-- CH4: double (nullable = true)\n",
      " |-- CO: double (nullable = true)\n",
      " |-- NMHC: double (nullable = true)\n",
      " |-- NO: double (nullable = true)\n",
      " |-- NO2: double (nullable = true)\n",
      " |-- Nox: double (nullable = true)\n",
      " |-- O3: double (nullable = true)\n",
      " |-- PH_RAIN: string (nullable = true)\n",
      " |-- PM10: integer (nullable = true)\n",
      " |-- PM2.5: double (nullable = true)\n",
      " |-- RAINFALL: string (nullable = true)\n",
      " |-- RAIN_COND: string (nullable = true)\n",
      " |-- RH: double (nullable = true)\n",
      " |-- SO2: double (nullable = true)\n",
      " |-- THC: double (nullable = true)\n",
      " |-- UVB: double (nullable = true)\n",
      " |-- WD_HR: double (nullable = true)\n",
      " |-- WIND_DIREC: double (nullable = true)\n",
      " |-- WIND_SPEED: double (nullable = true)\n",
      " |-- WS_HR: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|               SO2|          AMB_TEMP|              PM10|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|            214531|            197748|            213374|\n",
      "|   mean|3.4552978357440183|23.312762505815478|45.496306953986895|\n",
      "| stddev| 5.796185576838794|5.8679476400683255|163.48165810591306|\n",
      "|    min|               0.0|             -30.0|               -64|\n",
      "|    max|             368.0|              59.0|              9999|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('SO2', 'AMB_TEMP', 'PM10').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-------+------------------+-------------------+------------------+-------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+\n",
      "|summary|         time|station|          AMB_TEMP|                CH4|                CO|               NMHC|               NO|               NO2|               Nox|                O3|          PH_RAIN|              PM10|              PM25|          RAINFALL|         RAIN_COND|                RH|               SO2|               THC|               UVB|             WD_HR|       WIND_DIREC|       WIND_SPEED|             WS_HR|\n",
      "+-------+-------------+-------+------------------+-------------------+------------------+-------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+\n",
      "|  count|       216107| 216107|            197748|              94859|            214786|              94730|           214700|            214572|            214701|            197455|            34037|            213374|            213287|            206512|             34037|            197821|            214531|             94860|             25663|            180558|           180295|           180323|            180129|\n",
      "|   mean|         null|   null|23.312762505815478| 1.9349697972769042| 0.564809810695283|0.26849699144938616|9.078314392175002|  17.9479032679007|26.997343747816807|29.051350940720482| 4.41915180983252|45.496306953986895| 19.51441625603061|4.4398056625892695| 62.00591572123182|  75.8070260488017|3.4552978357440183| 2.202982289690041|1.3187273506604622|145.21167325734672|145.3958107545969|2.412507555885776|1.9870553880829502|\n",
      "| stddev|         null|   null|5.8679476400683255|0.21171637361324822|0.5461413336430129| 0.2399703566314034|17.80259263685419|12.089868411886085|26.738421026492063|17.876994479645365|1.129524692030328|163.48165810591306|60.047223796786135|24.706921029374744|125.52836622433603|13.759191044859712| 5.796185576838794|0.3873162486818372|2.3247583924959483| 86.68397620770435| 87.7415495193223| 1.67320831350203|1.6520584080246945|\n",
      "|    min|2015/1/1 0:00|Banqiao|             -30.0|                0.0|               0.0|              -8.24|              0.0|               0.0|               0.0|               0.0|                0|               -64|               0.0|                 0|                 0|               0.0|               0.0|              -0.1|               0.0|               0.0|              0.0|              0.0|               0.0|\n",
      "|    max|2015/9/9 9:00|   izhi|              59.0|               15.0|              38.0|               6.86|            358.0|             166.0|             411.0|             200.0|               NR|              9999|           10199.0|                NR|                NR|             100.0|             368.0|              20.0|              13.0|             360.0|            360.0|             29.0|              28.0|\n",
      "+-------+-------------+-------+------------------+-------------------+------------------+-------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 216107\n"
     ]
    }
   ],
   "source": [
    "print(\"Total data points:\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (10,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMB_TEMP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>Nox</th>\n",
       "      <th>O3</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>RH</th>\n",
       "      <th>SO2</th>\n",
       "      <th>WD_HR</th>\n",
       "      <th>WIND_DIREC</th>\n",
       "      <th>WIND_SPEED</th>\n",
       "      <th>WS_HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>197748.000000</td>\n",
       "      <td>214786.000000</td>\n",
       "      <td>214700.000000</td>\n",
       "      <td>214572.000000</td>\n",
       "      <td>214701.000000</td>\n",
       "      <td>197455.000000</td>\n",
       "      <td>213374.000000</td>\n",
       "      <td>213287.000000</td>\n",
       "      <td>197821.000000</td>\n",
       "      <td>214531.000000</td>\n",
       "      <td>180558.000000</td>\n",
       "      <td>180295.000000</td>\n",
       "      <td>180323.000000</td>\n",
       "      <td>180129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.312763</td>\n",
       "      <td>0.564810</td>\n",
       "      <td>9.078314</td>\n",
       "      <td>17.947903</td>\n",
       "      <td>26.997344</td>\n",
       "      <td>29.051351</td>\n",
       "      <td>45.496307</td>\n",
       "      <td>19.514416</td>\n",
       "      <td>75.807026</td>\n",
       "      <td>3.455298</td>\n",
       "      <td>145.211673</td>\n",
       "      <td>145.395811</td>\n",
       "      <td>2.412508</td>\n",
       "      <td>1.987055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.867948</td>\n",
       "      <td>0.546141</td>\n",
       "      <td>17.802593</td>\n",
       "      <td>12.089868</td>\n",
       "      <td>26.738421</td>\n",
       "      <td>17.876994</td>\n",
       "      <td>163.481658</td>\n",
       "      <td>60.047224</td>\n",
       "      <td>13.759191</td>\n",
       "      <td>5.796186</td>\n",
       "      <td>86.683976</td>\n",
       "      <td>87.741550</td>\n",
       "      <td>1.673208</td>\n",
       "      <td>1.652058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>2.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>358.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>10199.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>368.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AMB_TEMP             CO             NO            NO2  \\\n",
       "count  197748.000000  214786.000000  214700.000000  214572.000000   \n",
       "mean       23.312763       0.564810       9.078314      17.947903   \n",
       "std         5.867948       0.546141      17.802593      12.089868   \n",
       "min       -30.000000       0.000000       0.000000       0.000000   \n",
       "25%        19.000000       0.270000       1.400000       8.600000   \n",
       "50%        24.000000       0.420000       2.700000      15.000000   \n",
       "75%        28.000000       0.660000       7.500000      25.000000   \n",
       "max        59.000000      38.000000     358.000000     166.000000   \n",
       "\n",
       "                 Nox             O3           PM10           PM25  \\\n",
       "count  214701.000000  197455.000000  213374.000000  213287.000000   \n",
       "mean       26.997344      29.051351      45.496307      19.514416   \n",
       "std        26.738421      17.876994     163.481658      60.047224   \n",
       "min         0.000000       0.000000     -64.000000       0.000000   \n",
       "25%        10.000000      15.000000      26.000000       9.000000   \n",
       "50%        19.000000      28.000000      37.000000      16.000000   \n",
       "75%        33.000000      41.000000      52.000000      25.000000   \n",
       "max       411.000000     200.000000    9999.000000   10199.000000   \n",
       "\n",
       "                  RH            SO2          WD_HR     WIND_DIREC  \\\n",
       "count  197821.000000  214531.000000  180558.000000  180295.000000   \n",
       "mean       75.807026       3.455298     145.211673     145.395811   \n",
       "std        13.759191       5.796186      86.683976      87.741550   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%        67.000000       1.700000      76.000000      75.000000   \n",
       "50%        77.000000       2.600000     112.000000     112.000000   \n",
       "75%        86.000000       4.000000     220.000000     221.000000   \n",
       "max       100.000000     368.000000     360.000000     360.000000   \n",
       "\n",
       "          WIND_SPEED          WS_HR  \n",
       "count  180323.000000  180129.000000  \n",
       "mean        2.412508       1.987055  \n",
       "std         1.673208       1.652058  \n",
       "min         0.000000       0.000000  \n",
       "25%         1.200000       0.800000  \n",
       "50%         2.000000       1.500000  \n",
       "75%         3.100000       2.700000  \n",
       "max        29.000000      28.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pddf=pd.read_csv('AirQuality.csv')\n",
    "#spark_df = spark.createDataFrame(pddf)\n",
    "#spark_df.show()\n",
    "pddf.drop(['CH4','NMHC','THC','UVB','RAINFALL','RAIN_COND','PH_RAIN','station','time'],axis=1,inplace=True)\n",
    "pddf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 216107 entries, 0 to 216106\n",
      "Data columns (total 14 columns):\n",
      "AMB_TEMP      197748 non-null float64\n",
      "CO            214786 non-null float64\n",
      "NO            214700 non-null float64\n",
      "NO2           214572 non-null float64\n",
      "Nox           214701 non-null float64\n",
      "O3            197455 non-null float64\n",
      "PM10          213374 non-null float64\n",
      "PM25          213287 non-null float64\n",
      "RH            197821 non-null float64\n",
      "SO2           214531 non-null float64\n",
      "WD_HR         180558 non-null float64\n",
      "WIND_DIREC    180295 non-null float64\n",
      "WIND_SPEED    180323 non-null float64\n",
      "WS_HR         180129 non-null float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 23.1 MB\n"
     ]
    }
   ],
   "source": [
    "pddf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pddf.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 178059 entries, 0 to 216106\n",
      "Data columns (total 14 columns):\n",
      "AMB_TEMP      178059 non-null float64\n",
      "CO            178059 non-null float64\n",
      "NO            178059 non-null float64\n",
      "NO2           178059 non-null float64\n",
      "Nox           178059 non-null float64\n",
      "O3            178059 non-null float64\n",
      "PM10          178059 non-null float64\n",
      "PM25          178059 non-null float64\n",
      "RH            178059 non-null float64\n",
      "SO2           178059 non-null float64\n",
      "WD_HR         178059 non-null float64\n",
      "WIND_DIREC    178059 non-null float64\n",
      "WIND_SPEED    178059 non-null float64\n",
      "WS_HR         178059 non-null float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 20.4 MB\n"
     ]
    }
   ],
   "source": [
    "pddf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38979)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:38979)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_connected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-22b3109521f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msqlContest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mspark_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlContest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpddf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sparkContext, sparkSession, jsqlContext)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparkSession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0msparkSession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjsqlContext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mjsqlContext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msessionState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetConfString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1133\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    879\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \"\"\"\n\u001b[0;32m--> 881\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    833\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    834\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:38979)"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sqlContest = SQLContext(spark)\n",
    "spark_df = sqlContest.createDataFrame(pddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
